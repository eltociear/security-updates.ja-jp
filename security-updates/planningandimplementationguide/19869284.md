---
TOCTitle: Microsoft ISA Server パフォーマンス ベスト プラクティス
Title: Microsoft ISA Server パフォーマンス ベスト プラクティス
ms:assetid: '8b0f0f83-9927-47b7-8405-2a5478f1d925'
ms:contentKeyID: 19869284
ms:mtpsurl: 'https://technet.microsoft.com/ja-jp/library/Cc750615(v=TechNet.10)'
---

ISA Server パフォーマンス ベスト プラクティス
=============================================

ホワイト ペーパー : Internet Security and Acceleration Server 2000 パフォーマンス ベスト プラクティス

発行 : 2002 年 11 月

##### トピック

[](#ehaa)[はじめに](#ehaa)

[](#egaa)[キャパシティ戦略](#egaa)

[](#efaa)[ISA Server のスケーリング](#efaa)

[](#eeaa)[ISA Server リソースの調整](#eeaa)

[](#edaa)[ISA Server シナリオの調整](#edaa)

[](#ecaa)[ISA Server 機能の調整](#ecaa)

[](#ebaa)[ワークロードの見積もり](#ebaa)

[](#eaaa)[参考資料](#eaaa)

### はじめに

ISA Server キャパシティ プランニングの目的は、各組織のパフォーマンスおよびキャパシティに対する要求に応じて ISA Server 環境のハードウェア構成およびソフトウェア構成を計画するために必要な情報を用意することです。

ISA Server のキャパシティに関する典型的な質問として、「*n* 人のユーザーがいる組織で、ISA Server を運用するにはどのようなハードウェアが必要なのか」というものがあります。まず、この質問をいくつかの部分に分けて詳しく説明します。

**ハードウェア** - "リソース" ということもあります。ISA Server コンピュータのハードウェア コンポーネントのことであり、具体的には CPU、RAM、ネットワーク、ディスクなどを指しています。次のようなハードウェア構成が可能です。

-   1 台のコンピュータ内の単一または複数の CPU (スケール アップ)


-   単一または複数のコンピュータ (スケール アウト)


-   インターネット接続の既存の帯域幅または必要な帯域幅


-   特殊用途ハードウェア (SSL アクセラレータ、RAID ディスクなど)



**要件** - ISA Server "構成" に対する組織の要求を意味します。次に、適正なキャパシティを導き出すために重要となる要件の例をいくつか示します。

-   どのようなインターネット アクセス ポリシーが望ましいか


-   ISA Server でユーザーを認証する必要があるか


-   ISA Server の動作をログに記録する必要があるか


-   推奨されるサード パーティ製の Web/アプリケーション フィルタはあるか (ウイルス対策ソフト、コンテンツ フィルタなど)。



**ISA Server の運用** - ISA Server には、ファイアウォール、Web キャッシュ、Web 発行、サーバー公開、境界ネットワークという複数の "運用シナリオ" があり、それぞれパフォーマンス/キャパシティ特性が異なっています。これらの機能のうち組織がどれを必要としているかを見極める必要があります。

**組織** - ニーズは組織によって異なります。銀行とインターネット サービス プロバイダ (ISP) ではインターネット アクセス方法に違いがあります。たとえば、同種のユーザーから成るグループでは、要求をキャッシュで処理できることが多いため、異種のユーザーから成るグループより ISA Server リソースの消費量が少なくなる傾向があります。

**n 人のユーザー** - 予想ワークロード (負荷) を意味します。ユーザーの平均的なインターネット使用方法が解明されることはまれであるため、ユーザー数はあいまいになりがちで、キャパシティ プランニングの正確さを損ねる可能性があります。ユーザー数より役に立つメトリクスとして、現在使用しているインターネット接続の帯域幅があります。ISA Server を展開する環境として一般的なのは、ファイアウォールまたはキャッシュが使用されており、十分な帯域幅を持ったインターネット リンクがある環境です。

先ほどの質問は、より一般化された言葉を使って次のように言い換えることができます。「ある特定の "ワークロード" を受ける ISA Server "シナリオ" および "構成" をサポートするには、どのような "リソース" が必要なのか」 このホワイト ペーパーでは、この質問への回答を導き出すためのガイドラインを示します。

まず、それぞれ幅広い組織に合致する 3 つの簡明なキャパシティ戦略について説明します。「キャパシティ戦略」では、ユーザーのキャパシティ要件を明らかにし、キャパシティを重視した展開のガイドラインを作成します。ここでは、すべての ISA Server ユーザーを対象としています。

次の「ISA Server のスケーリング」では、将来においてキャパシティ ニーズが拡大した場合の対応について説明します。ここでは、大規模企業クラスのユーザーを対象としています。

その後の「ISA Server リソースの調整」、「ISA Server シナリオの調整」、および「ISA Server 機能の調整」では、ISA Server のパフォーマンスの調整について説明します。これらの節は、ISA Server 環境のキャパシティ拡大を担当する熟練技術者を対象としています。「ワークロードの見積もり」では、具体的な使用方法の分析に基づいてキャパシティを拡大する方法について説明します。

[](#mainsection)[ページのトップへ](#mainsection)

### キャパシティ戦略

ISA Server 環境にどのようなリソースが必要であるかを検討する際には、まず組織のキャパシティ要件を把握します。そのための方法として、それぞれ幅広い組織に合致するいくつかのキャパシティ戦略があります。

一般に、組織では以下のメトリクスを入手できます。

-   インターネット リンクのネットワーク帯域幅


-   内部インターネット ユーザーの人数


-   Web サービスに対する (1 日あたりの) アクセス ヒット数 (主として公開シナリオ)



この中で ISA Server のキャパシティ プランニングにおいて最も有益なメトリクスは、インターネット接続の帯域幅です。ほとんどの場合、この帯域幅はインターネット キャパシティに対する組織のニーズを直接表しています。帯域幅は高コストのリソースであり、効率的に使用されるからです。

組織内のインターネット ユーザー数はキャパシティ プランニングにとって有益なメトリクスではありません。インターネット ユーザーの人数は、使用方法やインターネット使用ポリシーなどによって組織ごとに大きく異なるからです。

アクセス ヒット数も単独では役に立ちません。ただし、多くの場合、アクセス ヒット数を基に、ピーク要求率や要求タイプ分布などの有益なメトリクスを導き出すことができます。

ISA Server のキャパシティ プランニングは、必ず以下のいずれかのカテゴリに分類できます。

-   インターネット接続の帯域幅が小さく、ISA Server システムのボトルネックとなる場合は、単一エントリ レベル ISA Server コンピュータ戦略に該当します。


-   インターネット接続の帯域幅が 1 台のコンピュータによる使用量より大きく、ISA Server をフォワード キャッシュ シナリオまたはアウトバウンド ファイアウォール シナリオで使用する場合は、大規模企業戦略に該当します。


-   インターネット接続の帯域幅が 1 台のコンピュータによる使用量より大きく、ISA Server を公開シナリオで使用する場合は、公開戦略に該当します。



これらの戦略について以下で詳しく説明します。

#### 単一エントリ レベル ISA Server コンピュータ

単一 ISA Server コンピュータによるこのキャパシティ戦略が適しているのは、インターネット接続の帯域幅が小さい組織において、アウトバウンド ファイアウォール シナリオまたはフォワード キャッシュ シナリオで ISA Server を使用する場合です。最近実施されたインターネット利用に関する市場調査によると、米国企業が使用しているインターネット リンクの帯域幅はほとんどが 1 ～ 10 Mbps であるということです。この事実だけで、ほとんどの ISA Server 環境には単一プロセッサまたはデュアル プロセッサのエントリ レベル コンピュータで十分であることがわかります。

アウトバウンド ファイアウォール テストを行ったところ、ISA Server ファイアウォール サービスを単一 Pentium III 733 MHz プロセッサで実行した場合、70% の CPU 使用率でスループット (HTTP とストリーミング データの混合) が最大 25 Mbps となることがわかりました (このスループットはワーストケースの SecureNAT クライアントで計測したものです)。これは、1.5 Mbps の T1 インターネット リンクの場合、このファイアウォール サービスが CPU を最大 5% しか使用しないことを意味します。

フォワード キャッシュ テストでは、単一 Pentium III 733 MHz プロセッサを搭載したエントリ レベルの ISA Server コンピュータを使用した場合、CPU 使用率 75% で、1 秒あたり最大 660 の HTTP 要求に対応可能であることがわかり、ヒット率は 35%、キャッシュ不能応答率は 50%、平均応答サイズは 7.6 KB となりました。したがって、スループットはサーバー上では約 39 Mbps ですが、インターネット リンク上では 25 Mbps にしかなりません。ただし、これはシステム ハードウェア リソースが CPU 使用率の最大化を目的として設計されていることを前提としています (詳細については、「CPU 使用率の最大化を目的としたシステム設計」を参照してください)。

![](images/Cc750615.isprfp01(ja-jp,TechNet.10).gif)

660 - 1 秒あたりの要求数

65% - キャッシュ ヒットではない (キャッシュ ミスおよびキャッシュ不能) 要求の割合

7.6 x 1, 024 - 平均応答サイズ 7.6 KB

8/10242 - 1 秒あたりのバイト数から 1 秒あたりのメガビット数 (Mbps) への変換

インターネット リンクが帯域幅 1.5 Mbps の専用 T1 接続である場合、次のような計算式によって、ISA Server システムが 1 秒間に最大 39 の要求を処理できることがわかります。

![](images/Cc750615.isprfp02(ja-jp,TechNet.10).gif)

この要求率では、ISA Server は CPU を 5 ～ 10% しか使用しないため、残りの CPU は同じコンピュータで実行される他のプロセスによって使用可能です。このように CPU 使用率が低いため、CPU 使用率が 50 ～ 70% で、T1 リンクのプロセッサが 733 MHz Pentium III である場合、透過的キャッシュを有効にすることもできます (透過的キャッシュ パフォーマンスの詳細については、「クライアントの調整」を参照してください)。

単一エントリ レベル コンピュータ戦略は、インターネット接続の帯域幅が 1 台のエントリ レベル コンピュータの処理能力だけで 100% 使用されるほど小さい場合に適用できます。この戦略に基づく作業手順は単純です。"任意のエントリ レベル コンピュータに ISA Server をインストールして設定を完了する" だけです。

この戦略は、いくつもの支社があり、それぞれに独立した低帯域幅インターネット リンクがある大企業にも適用できます。このような場合には、各支社を 1 つの小規模な組織と考えることができ、それぞれのインターネット接続は 1 台のエントリ レベル ISA Server コンピュータによって 100% 使用されます。

もう 1 つ検討しなければならない点があります。コンピュータのパフォーマンスとそれによってサポートされるインターネット接続帯域幅との関係です。次の表は、各シナリオでインターネット接続の使用率が 100% である場合の Pentium III 733 MHz プロセッサの CPU 使用率を示しています (スループットはインターネット リンク上で計測されたものです)。

**表 1 ネットワークに拘束されたシステムの CPU 使用率**

<table style="width:100%;">
<colgroup>
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th style="border:1px solid black;" ></th>
<th style="border:1px solid black;" >CPU 使用率 75% でのインターネット Mbps</th>
<th style="border:1px solid black;" >1.5 Mbps (T1) での CPU 使用率</th>
<th style="border:1px solid black;" >4.5 Mbps での CPU 使用率</th>
<th style="border:1px solid black;" >15 Mbps での CPU 使用率</th>
<th style="border:1px solid black;" >45 Mbps (T3) での CPU 使用率</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="border:1px solid black;">アウトバウンド/インバウンド ファイアウォール (SecureNAT クライアント)</td>
<td style="border:1px solid black;">29</td>
<td style="border:1px solid black;">4</td>
<td style="border:1px solid black;">12</td>
<td style="border:1px solid black;">38</td>
<td style="border:1px solid black;">115</td>
</tr>
<tr class="even">
<td style="border:1px solid black;">アウトバウンド ファイアウォール (ファイアウォール クライアント)</td>
<td style="border:1px solid black;">61</td>
<td style="border:1px solid black;">2</td>
<td style="border:1px solid black;">6</td>
<td style="border:1px solid black;">19</td>
<td style="border:1px solid black;">56</td>
</tr>
<tr class="odd">
<td style="border:1px solid black;">フォワード キャッシュ</td>
<td style="border:1px solid black;">25</td>
<td style="border:1px solid black;">4</td>
<td style="border:1px solid black;">13</td>
<td style="border:1px solid black;">45</td>
<td style="border:1px solid black;">134</td>
</tr>
<tr class="even">
<td style="border:1px solid black;">リバース キャッシュ</td>
<td style="border:1px solid black;">71</td>
<td style="border:1px solid black;">2</td>
<td style="border:1px solid black;">5</td>
<td style="border:1px solid black;">16</td>
<td style="border:1px solid black;">48</td>
</tr>
<tr class="odd">
<td style="border:1px solid black;">統合ファイアウォール/キャッシュ</td>
<td style="border:1px solid black;">32</td>
<td style="border:1px solid black;">4</td>
<td style="border:1px solid black;">11</td>
<td style="border:1px solid black;">36</td>
<td style="border:1px solid black;">107</td>
</tr>
</tbody>
</table>
  
"CPU 使用率 75% でのインターネット Mbps" の列は、Pentium III 733 MHz プロセッサがサポート可能なインターネット帯域幅を示します。その後の 4 つの列は、各帯域幅のインターネット接続を 100% 使用した場合の予想 CPU 使用率を示します。この表を見ると、Pentium III 733 MHz プロセッサを使用した場合、ほとんどのインターネット リンクですべてのシナリオに対応できることがわかります。ハイエンド (T3 リンク) では、Pentium 4 を搭載していればどのようなコンピュータでも対応できます。
  
#### 大規模企業
  
Microsoft のレドモンド サイトのような大規模企業レベルのサイトでは、環境がもっと複雑です。このようなサイトの場合、インターネット帯域幅が大きいため、パフォーマンス ボトルネックが ISA Server システムの CPU リソースに移ることから、ISA Server キャパシティ戦略を入念に計画することが必要です。この戦略は、ファイアウォール シナリオだけでなくキャッシュ (フォワードおよびリバース) シナリオにも適用できます。
  
インターネット接続の帯域幅は、接続の使用率が 100% となるコンピュータの最大数を決定する要因にもなります。ほとんどのキャパシティ見積もりでは、この最大数でも十分です。さらに、必要なキャパシティは時間の経過と共に増加していく傾向にあるため、最大ネットワーク キャパシティの見積もりはかなり控えめな値となります。したがって、処理能力のアップグレードを容易にし、将来的な要求の増大に備えることも必要です。「ISA Server のスケーリング」では、ハードウェア スケーリングの手法、各手法のパフォーマンス特性、およびスケーリングのメリットについて説明します。
  
ISA Server のキャパシティ プランニングをより正確なものにするうえで鍵となるのが、ワークロードを見積もることです。「ワークロードの見積もり」では、その方法について説明します。ただし、リソースの不足や必要な情報を入手できないために、ワークロードの計測が不可能である場合が少なくありません (大規模な ISA Server システムを新たに構築する場合など)。フォワード シナリオ (アウトバウンド ファイアウォールおよびフォワード キャッシュ) では、ワークロードが組織によってそれほど変わらないため、ワークロードを見積もっても役に立たない場合があります。
  
#### 公開
  
公開シナリオは、クライアントとサーバーとの間の接続としてインターネット リンクを使用する点でフォワード シナリオとは異なります。1 日あたり数百万のヒットに対応する大規模な Web サイトでは、1 秒間に数千件の要求を処理する能力を持ったインターネット リンクを使用します。このような場合は、ISA Server を高速化のために使用するのではなく、Web サイトからのキャッシュ可能な要求による負荷の軽減を目的として使用します。インターネット リンクの速度が 70 Mpbs を下回る場合、公開シナリオには単一コンピュータ戦略で対応できます。一方、大規模な Web サイトの場合は、リンクの最高速度が 70 Mbps であっても、2 台のコンピュータに ISA Server を展開し、フォールト トレランスを高めることによって、パフォーマンスが向上します。ファイアウォール サーバー公開シナリオの場合は、単一 Pentium III 733 MHz コンピュータの最大スループットは 29 Mbps となります。
  
ただし、大規模な公開サイトには、大規模企業の場合と似たキャパシティ戦略を使用します。この場合も、ほとんどの大規模企業では、インターネット最大帯域幅を考慮に入れた控えめな見積もりから始め、ハードウェア スケーリング戦略を作成するだけで十分です。
  
ただし、公開シナリオの場合は、フォワード シナリオとは異なり、コンテンツ特性の違いによってワークロードが大きく変動します。そのため、要求率がほぼ同じ Web サイトでも、キャパシティはサイトによって大きく異なります。控えめな見積もりに基づいて選択したハードウェアの価格が高すぎる場合は、ワークロードの計測結果を基に、より正確な見積もりを行うことによって、必要なハードウェアの購入コストを大幅に削減できる場合もあります。
  
[](#mainsection)[ページのトップへ](#mainsection)
  
### ISA Server のスケーリング
  
システムの CPU 能力を高める方法は 2 つあります。まず、プロセッサを増設するという方法です (コンピュータの筐体がマルチプロセッサに対応していることが必要です)。これを処理能力の "スケール アップ" といいます。もう 1 つは、コンピュータを追加するという方法です (コンピュータをクラスタ構成にしていることが必要です)。これを "スケール アウト" といいます。
  
ISA Server では、スケール アップとスケール アウトの両方をサポートしています。それぞれの方法について以下で詳しく説明します。
  
#### スケール アップ
  
Windows Server System は対称型マルチプロセッシング (SMP) に対応しています。対称型マルチプロセッシングとは、オペレーティング システムがいずれか使用可能なプロセッサ上でスレッドを実行できることをいいます。その結果、アプリケーションは処理能力が不足した場合に複数のプロセッサを使用できるため、システムのスループットが向上します。
  
ただし、すべてのプロセッサが共有するメモリや I/O デバイスなどのハードウェア リソースが阻害要因となるため、プロセッサ数を倍にしたからといってアプリケーションが処理できるトランザクション数が必ずしも倍になるわけではありません。1. むしろ、アプリケーションの処理能力の向上が直線的スケーリングとなることの方がまれです。ISA Server の場合、シナリオにもよりますが、スケール係数は 1.6 ～ 1.7 です。
  
#### スケール アウト
  
ISA Server システムをスケール アウトするには、次のような方法があります。
  
-   **高レベル ネットワーク スイッチング ハードウェアを使用する** このようなスイッチを L4/7 (レイヤ 4 ～ 7) スイッチと呼ぶことがあります。これは、ネットワーク レイヤ情報 (TCP) またはアプリケーション レイヤ情報 (HTTP) に基づいてパケット交換を行うことができるからです。これらのレベルで取得できる情報を基に、送信元/送信先の IP アドレス、URL、コンテンツの種類などに従って、高度な負荷分散を行うことができます。このようなスイッチはハードウェア アプライアンスとして実装されるため、スループットが比較的高く、可用性や信頼性にも優れていますが、価格も高めです。ほとんどのスイッチにはサーバー ダウンを検出する機能があるため、フォールト トレランスも実現できます。
  

-   **DNS ラウンド ロビン名前解決を使用してサーバー クラスタに DNS 内の同じ名前を割り当てる** その名前が要求されるたびに、DNS がリスト内の順序を変更し、異なる IP アドレスを返します。このソリューションは低コストですが (実際にはまったくコストはかかりません)、多くのデメリットがあります。大きな問題の 1 つは、負荷がクラスタ内のサーバーに必ずしも均等に分散されないことです。フォールト トレランスの効果がないことも問題です。
  

-   **Windows ネットワーク負荷分散を使用する** ネットワーク負荷分散では、クラスタ内のすべてのサーバーが 1 つの IP アドレスを共有し、この IP アドレス宛てに送信されたパケットはすべてのサーバーによって認識されます。ただし、パケットを処理するのは何らかの共有ハッシュ関数によって指定された 1 つのサーバーだけです。ネットワーク負荷分散はオペレーティング システム レベルで実装されます。均等な負荷分散が可能で、フォールト トレランスも実現されます (クラスタ内のいずれかのサーバーで障害が発生した場合、残りのサーバー間で負荷が分散されます)。ただし、ネットワーク負荷分散は CPU 処理オーバーヘッド (通常の ISA Server シナリオの 10 ～ 15%) を必要とし、クラスタを構成するサーバーの数にも限界があります (推奨最大数は約 12 台)。ネットワーク負荷分散は Windows Advanced Server でのみ提供されています。
  

-   キャッシュ シナリオでは、ISA Server はキャッシュ負荷分散プロトコルである CARP (キャッシュ アレイ プロトコル) をサポートします。CARP はサーバー間で負荷を分散するだけでなく、キャッシュ内のコンテンツも分散します。要求はクラスタ内の特定のコンピュータに送信され、それ以降のヒットはそのコンピュータで処理されます。CARP は ISA Server Enterprise Edition でのみ提供されています。
  

  
#### スケール アップとスケール アウトの比較
  
スケーリングの目的はシステムのキャパシティを拡大することです。どのスケーリング方法にもメリットとデメリットがあり、ISA Server の場合はシナリオによっても最適なスケーリング方法が異なります。どのスケーリング方法を採用するかを決定するときには、以下の点を考慮してください。
  
-   **パフォーマンスへの効果** - プロセッサまたはコンピュータを追加することによってスループットをどの程度まで高めることができるか検討します。
  

-   **システム コスト** - システムの導入に要する初期費用のことであり、"保有コスト" とは異なります。
  

-   **システム管理** - システム管理の複雑度を意味します。この点がシステムの保有コストと直接関係します。
  

-   **フォールト トレランス** - システムの可用性および信頼性を高める方法です。
  

-   **システム アップグレード** - システムの処理能力を高める方法です。アップグレード コストも重要な考慮点の 1 つです。
  

  
次に、スケール アップとスケール アウトのどちらを採用するかを決定する際に検討を加える必要のあるトレードオフについて説明します。
  
1.  **パフォーマンス**
  
    1 台のマルチプロセッサ コンピュータのスケール係数は、一般にコンピュータ クラスタより小さくなります。したがって、数基のプロセッサで十分であるうちは単一コンピュータの方が望ましいと言えますが、あるスケールを超えると、単一コンピュータではクラスタの高いスケール係数がもたらすようなパフォーマンスの向上は期待できません。
  
2.  **システム コストと保有コストの比較**
  
    一般に、多くのプロセッサを搭載していても、1 つの筐体の方が複数のコンピュータから成るクラスタより構成や保守が容易です。その一方で、マルチプロセッサ コンピュータは単一プロセッサ コンピュータよりはるかに高価です (一般に、プロセッサ単位で比較してもマルチプロセッサ コンピュータの方が割高です)。
  
3.  **単一障害点とフォールト トレランスの比較**
  
    単一コンピュータを使用した場合、ハードウェア障害によって可用性が損なわれる可能性が、複数のコンピュータで構成されるクラスタの場合よりはるかに高くなります。システム ボードやディスク コントローラで障害が発生すると、システム全体が動作しなくなり、修復が必要となります。同じことはハードウェア負荷分散ソリューションにも言えます。
  
4.  **アップグレード**
  
    単一コンピュータ ソリューションの場合、プロセッサ スロットが空いていれば (またはハードウェア負荷分散スイッチに空いたポートがあれば)、アップグレードはきわめて簡単です。プロセッサ スロットやポートが空いていない場合は、筐体を交換する必要があり、アップグレードには多大なコストがかかります。複数のコンピュータから成るクラスタをアップグレードする場合は、コンピュータを追加するという点で煩雑な作業になりますが、購入コストは平均すると大幅に安くなります。
  
次の表は、これまでの説明を要約したものです。
  
**表 2 ISA Server スケーリング オプション**
  
<table style="width:100%;">
<colgroup>
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
<col width="16%" />
</colgroup>
<tbody>
<tr class="odd">
<td style="border:1px solid black;"><strong></strong></td>
<td style="border:1px solid black;">スケール アップ</td>
<td style="border:1px solid black;">スケール アウト</td>
<td style="border:1px solid black;"><strong></strong></td>
<td style="border:1px solid black;"><strong></strong></td>
<td style="border:1px solid black;"><strong></strong></td>
</tr>
<tr class="even">
<td style="border:1px solid black;"><strong></strong></td>
<td style="border:1px solid black;"><strong></strong></td>
<td style="border:1px solid black;">L4/7 スイッチ</td>
<td style="border:1px solid black;">DNS</td>
<td style="border:1px solid black;">ネットワーク負荷分散</td>
<td style="border:1px solid black;">CARP</td>
</tr>
<tr class="odd">
<td style="border:1px solid black;">パフォーマンス (スケール係数)</td>
<td style="border:1px solid black;">1.6 ～ 1.7。コンピュータ アーキテクチャによって異なります (2 次キャッシュのサイズが大きいほど、スケール係数は大きくなります)。</td>
<td style="border:1px solid black;">2</td>
<td style="border:1px solid black;">2</td>
<td style="border:1px solid black;">1.8 (クラスタのコンピュータ数が 1 ～ 8 台の場合)</td>
<td style="border:1px solid black;">1.5 から始まり、漸近的に 2 へ近づいていきます。</td>
</tr>
<tr class="even">
<td style="border:1px solid black;">システム コスト</td>
<td style="border:1px solid black;">マルチプロセッサ コンピュータの方がはるかに高コストです (特に 4 プロセッサ以上)。2</td>
<td style="border:1px solid black;">きわめて高価 ($15,000 ～ $100,000)</td>
<td style="border:1px solid black;">なし</td>
<td style="border:1px solid black;">各コンピュータに Windows 2000 Advanced Server が必要です。</td>
<td style="border:1px solid black;">ISA Server Enterprise Edition (EE) が必要です。</td>
</tr>
<tr class="odd">
<td style="border:1px solid black;">システム管理</td>
<td style="border:1px solid black;">単一コンピュータの管理</td>
<td style="border:1px solid black;">複数のコンピュータに加えてスイッチの管理も必要です。</td>
<td style="border:1px solid black;">複数のコンピュータと ISA Server 集中化アレイの管理 (EE)</td>
<td style="border:1px solid black;">複数のコンピュータと ISA Server 集中化アレイの管理 (EE)</td>
<td style="border:1px solid black;">複数のコンピュータと ISA Server 集中化アレイの管理 (EE)</td>
</tr>
<tr class="even">
<td style="border:1px solid black;">フォールト トレランス</td>
<td style="border:1px solid black;">ネイティブ ハードウェア</td>
<td style="border:1px solid black;">スイッチが障害の発生したコンピュータを検出し、残りのコンピュータに負荷を分散します。</td>
<td style="border:1px solid black;">なし</td>
<td style="border:1px solid black;">障害が発生したコンピュータの相互検出</td>
<td style="border:1px solid black;">障害が発生したコンピュータの相互検出</td>
</tr>
<tr class="odd">
<td style="border:1px solid black;">システム アップグレード</td>
<td style="border:1px solid black;">プロセッサの増設 - スロットが空いていることが必要です。</td>
<td style="border:1px solid black;">コンピュータの追加 - 空いたポートがあり、スイッチの帯域幅に余裕があることが必要です。</td>
<td style="border:1px solid black;">コンピュータを追加し、DNS にエントリを登録します。</td>
<td style="border:1px solid black;">コンピュータの追加 - コンピュータが多くなりすぎると、スケール係数が低下することがあります。</td>
<td style="border:1px solid black;">コンピュータの追加 - ほとんど無制限のスケーリングが可能です。</td>
</tr>
<tr class="even">
<td style="border:1px solid black;">シナリオ</td>
<td style="border:1px solid black;">すべて</td>
<td style="border:1px solid black;">すべて</td>
<td style="border:1px solid black;">すべて</td>
<td style="border:1px solid black;">すべて</td>
<td style="border:1px solid black;">フォワード キャッシュのみ</td>
</tr>
</tbody>
</table>
  
[](#mainsection)[ページのトップへ](#mainsection)
  
### ISA Server リソースの調整
  
キャッシュ プランニングでは、まずパフォーマンス要件を満たす必要のあるコンピュータ システムの種類を特定します。次のステップは、システムを構成し、稼働を開始した後で、最高のパフォーマンスを引き出すことです。ISA Server では、システムが CPU 能力に拘束されるように適切なハードウェア リソースを設計します (ただし、単一エントリ レベル ISA Server 戦略は例外です。最低速の CPU でも 100% 使用できるほどインターネット接続の帯域幅が小さいからです)。この考え方については以下で詳しく説明します。
  
リソースの調整だけでなく、シナリオの調整および機能の調整も高度な内容であり、検討が必要となるのは大規模企業レベルの展開の場合だけです。単一エントリ レベル コンピュータ展開では、ほとんどの場合、パフォーマンスの向上を目的とする ISA Server の調整は不要です。
  
#### CPU 使用率の最大化を目的としたシステム設計
  
ISA Server のキャパシティは、ハードウェア リソースである CPU、ネットワーク、ディスク、およびメモリに依存します。これらのリソースのそれぞれにキャパシティの限界があり、どのリソースもそれぞれの最大キャパシティ以下で使用されますが、システム全体としては適切に動作し、パフォーマンス目標を達成します。いずれかのリソースがキャパシティの限界に達すると、ボトルネックとなり、システムのパフォーマンスが著しく低下します。このような状態をシステムがそのリソースに "拘束されている" といいます。ボトルネックはシステム全体のパフォーマンスにおいて必ず何らかの症状として現れるため、それをもとにキャパシティが不足しているリソースを検出することができます。このような場合には、そのリソースのキャパシティを増やす必要があります。
  
価格はリソースによって異なりますが、現在のコンピュータ市場では、CPU が最も高価なコンピュータ リソースです。そのため、どのリソースのキャパシティを拡張するかを検討する場合、CPU は最後の候補となります。したがって、CPU 使用率の最大化を目標としてシステムを設計し、CPU 使用率が 100% に達するまでにパフォーマンス ボトルネックが発生しないようにする必要があります。つまり、CPU の能力が高く、予想される負荷に耐えることができれば、ボトルネックはまったく発生しません。そのためには、CPU 以外のすべてのリソースが十分なキャパシティを備えていることが必要です。ここでは、各リソースが十分なキャパシティを備え CPU を最大限に使用できるシステムを設計する方法、各リソースを監視する方法、および各リソースがボトルネックとなった場合のトラブルシューティングの方法について説明します。
  
#### CPU キャパシティの見積もり
  
大量のクライアント要求を処理するほとんどのサーバー アプリケーションと同様、ISA Server の場合も、プロセッサ キャッシュのサイズが大きく、CPU の速度が速く、プロセッサ アーキテクチャが先進的であるほど、パフォーマンスが向上します。次に、ISA Server システムに最適な CPU を選択するためのガイドラインを示します (パフォーマンスに対する効果の高いものから順に挙げてあります)。
  
1.  **2 次キャッシュ/3 次キャッシュのサイズ** 大量のデータを扱うためには、頻繁なメモリ アクセスが必要となります。2 次キャッシュや 3 次キャッシュがあると、頻度の高いメモリ フェッチのパフォーマンスが向上します。
  
2.  **CPU 速度** 他のアプリケーションと同じように、ISA Server も CPU の速度が速いほどパフォーマンスは向上します。ただし、CPU の速度が速くなっても、それに比例してパフォーマンスが向上するわけではありません。大量のメモリに頻繁にアクセスする場合、CPU を高速化すると、CPU サイクルを待つときに無駄なアイドル メモリが増加することがあります。この現象は、プロセッサを Intel Pentium III を 733 MHz から 933 MHz に高速化したときに実際に確認されました。
  
3.  **先進的なアーキテクチャ** 他のアプリケーションと同じように、ISA Server も最新のアーキテクチャに基づく CPU を使用することによってパフォーマンスが向上します。Pentium III を使用したシステムより Intel Pentium 4 を使用したシステムの方が高いパフォーマンスを示します。ISA Server のキャパシティ テストを行ったところ、Pentium 4 1.7 GHz プロセッサと Pentium III 733 MHz プロセッサの比較において、Pentium 4 1.7 GHz プロセッサを使用した方が、ファイアウォール テストでは 20%、キャッシュ テストでは 45%、パフォーマンスが向上しました。
  
ネットワーク アダプタ カードおよびディスク I/O がキャパシティの限界に達しておらず、パフォーマンス カウンタ \\Processor\\% Processor Time が高い値を示している場合に、CPU がボトルネックとなっていると判断できます。この場合 (CPU が最大限に使用されているシステムにおいて)、CPU 使用率が 100% に達したということは、CPU のアップグレードが必要であることを意味します。これは単一 CPU についてのアップグレード ガイドラインですが、CPU の増設によって処理能力を高めることも可能です。「スケール アップとスケール アウトの比較」で、CPU のスケーリング オプションについて説明しました。応答が遅く、ISA Server のパフォーマンスが低下していると考えられるにもかかわらず、CPU の使用率が低い場合は、CPU 以外のリソースがボトルネックであると判断できます。
  
#### ネットワーク キャパシティの見積もり
  
接続上に配置されたネットワーク周辺機器には、それぞれにキャパシティの限界があります。ネットワーク周辺機器とは、クライアントおよびサーバーの NIC やルーターの他、それらを相互接続するスイッチおよびハブなどをいいます。ネットワーク キャパシティが十分であるとは、これらのネットワーク デバイスが 1 つとして飽和状態にならないことを意味します。ネットワーク デバイスの負荷を最大キャパシティ以内に抑えるためには、ネットワークの稼働状況を監視することが必要です。
  
十分なネットワーク キャパシティはワークロード パラメータの関数です。たとえば、クライアントを 100 Mbps Fast Ethernet リンク上の ISA Server に接続している場合のフォワード キャッシュについて考えてみます。このリンクは、次の式で表されるように、ネットワーク使用率がピーク時の推奨値である 75% のとき、1 秒あたりの HTTP 応答数 1,200 (平均応答サイズ 8 KB) というピーク要求率を達成します。
  
![](images/Cc750615.isprfp03(ja-jp,TechNet.10).gif)
  
最大負荷における平均要求率がユーザーあたり毎分 6 件である場合、1 秒あたりの HTTP 要求数が 1,200 であれば、12,000 人のユーザーからの要求に対応できます。
  
![](images/Cc750615.isprfp04(ja-jp,TechNet.10).gif)
  
上記の結果は、要求の平均サイズ (8 KB) と平均ユーザー要求率 (1 分あたり 6 件) の関数であり、ワークロードの大きさによって異なります。
  
フォワード キャッシュ シナリオの場合、インターネット リンクは一般にかなり低速ですが、さいわいなことにインターネット リンクを介して転送される応答トラフィックの割合はほんのわずかです。たとえば、ヒット率が 40% である場合、先ほど例に挙げた 12,000 人の同時ユーザーが生成するスループットは次のようになります。
  
![](images/Cc750615.isprfp05(ja-jp,TechNet.10).gif)
  
ネットワーク キャパシティが 75% のときに 45 Mbps の転送速度を達成する場合、推奨されるインターネット リンクの帯域幅は 60 Mbps です。ほとんどの場合、インターネット リンクの帯域幅は高価なリソースであるため、軽視できないものであり、組織としては効率的に使用する必要があります。前の例では、ピーク スループットにおける使用率が 75% のとき、T3 リンク (45 Mbps) は 1 秒あたり 900 件というピーク要求率に対応できます。
  
![](images/Cc750615.isprfp06(ja-jp,TechNet.10).gif)
  
ネットワークの稼働状況を監視するには、パフォーマンス カウンタ \\Network Interface\\Bytes Total/sec を使用します。このカウンタの値がネットワーク カードの最大帯域幅の 75% に相当する値を超えた場合は、インターネット リンク帯域幅の増大を検討する必要があります。
  
#### ディスク キャパシティの見積もり
  
ディスク パフォーマンスは、シナリオ、ヒット率、ピーク要求率、作業セット サイズという複数の要因によって決まります。
  
ファイアウォール シナリオには、ディスク キャパシティは関係しません (このシナリオでは負荷の小さいログ操作でしかディスクを使用しません)。キャッシュ シナリオの場合、フォワード キャッシュとリバース キャッシュではワークロードの特性に違いがあるため、キャッシュの調整についての原則がまったく異なります。
  
#### フォワード キャッシュにおけるディスクの調整
  
フォワード キャッシュでは、ヒット率とピーク要求率に基づいて必要なディスクの数を見積もります。たとえば、ISA Server コンピュータで 15,000 RPM ディスク ドライブ (毎秒 150 I/O) を使用する場合、ヒット率が 40% のとき、次の式によって、最大負荷において 1 秒あたり 900 件の要求を処理するためには 3 つのディスクが必要であることがわかります。
  
![](images/Cc750615.isprfp07(ja-jp,TechNet.10).gif)
  
種類およびキャパシティが同じディスクを使用し、他の目的には使用しないことをお勧めします。RAID ストレージ サブシステムを使用する場合は、RAID-0 (フォールト トレランスなし) として構成します。ディスクを節約する必要があり、1 つのディスクをシステム ファイルと ISA Server キャッシュの両方の目的に使用する場合は、ディスク リソースの使用率が高いアプリケーションを実行しないことが必要です。
  
必要なディスク数の見積もりが完了したら、可能な最高ヒット率を達成できるようにディスク キャッシュの合計サイズを調整することができます。この調整を行うには、以下の手順を実行します。
  
1.  まず、初期キャッシュ サイズをフォーマット済みディスク領域の合計サイズの約 50% に設定します。キャッシュの合計サイズを各ディスクに均等に振り分けます。
  
2.  負荷がピークとなる時間帯のヒット率を確認します。
  
3.  ディスク キャパシティを数パーセント増やします。ヒット率が低すぎる場合は拡大率を大きめに設定し (50%)、ヒット率が少し低い場合は 20% に設定します。
  
4.  もう一度ヒット率を調べます (ヒット率は必ず翌日に確認してください)。ヒット率が大幅に向上した場合は (上昇率が数パーセントにとどまらない場合)、ステップ 3 に戻ってください。そうでない場合は、調整は終了です。ヒット率は実際の値に漸近的に近づきます。
  
#### リバース キャッシュにおけるディスクの調整
  
リバース キャッシュ シナリオでは、フォワード キャッシュ シナリオの場合に比べて作業セット サイズが小さいため、すべての作業セットをメモリに置くことも可能です。ただし、ISA Server ではディスク キャッシュがフォワード キャッシュ シナリオの場合と同じ方法で使用されます。しかし、メモリ キャッシュのサイズが作業セット全体を格納できるほど大きければ、ディスク キャッシュ オブジェクトはメモリに一度しか読み込まれません。
  
作業セット サイズとは、キャッシュがホストする Web サイトのキャッシュ可能オブジェクトの総数を意味します。すべてのキャッシュ可能オブジェクトを格納できることに加え、ディスク割り当てとキャッシュ リフレッシュ ポリシーにおける断片化を考慮に入れると、ディスク キャッシュの推奨サイズは作業セット サイズの約 2 倍となります。3したがって、作業セット サイズが 1 GB である場合は、ディスク キャッシュは 2 GB あれば十分であると言えます。
  
ほとんどのキャッシュ フェッチはメモリ キャッシュで行われるため (サイズが十分に大きい場合 - メモリ キャッシュ キャパシティの調整方法については次の「メモリ容量の見積もり」を参照)、ディスク読み取り率は低い値でしかありません。通常は、このようなフェッチには 1 つのディスクだけで対応でき、それがボトルネックとなることもありません。
  
#### メモリ容量の見積もり
  
ISA Server ではメモリを以下の目的で使用します。
  
-   ネットワーク ソケットの保存 (多くは非ページ プールから)
  

-   内部データ構造
  

-   未処理の要求オブジェクト
  

-   ディスク キャッシュ ディレクトリ構造
  

-   メモリ キャッシュ
  

  
(最後の 2 つはキャッシュ シナリオにのみ該当します。)
  
#### ファイアウォール メモリの調整
  
ファイアウォール シナリオでは、合計メモリ サイズの関数である非ページ プールのサイズによってメモリのサイズが決まります。Microsoft サポート技術情報の Knowledge Base の文書 JP126402 によると、非ページ プール サイズの最小値および最大値は以下のとおりです。
  
**表 3 物理メモリ サイズに基づく非ページ プール サイズの最小値および最大値**
  
<table style="width:100%;">
<colgroup>
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
</colgroup>
<tbody>
<tr class="odd">
<td style="border:1px solid black;">物理メモリ (MB)</td>
<td style="border:1px solid black;">128</td>
<td style="border:1px solid black;">256</td>
<td style="border:1px solid black;">512</td>
<td style="border:1px solid black;">1024</td>
<td style="border:1px solid black;">2048</td>
<td style="border:1px solid black;">4096</td>
</tr>
<tr class="even">
<td style="border:1px solid black;">非ページ プール サイズの最小値</td>
<td style="border:1px solid black;">4</td>
<td style="border:1px solid black;">8</td>
<td style="border:1px solid black;">16</td>
<td style="border:1px solid black;">32</td>
<td style="border:1px solid black;">64</td>
<td style="border:1px solid black;">128</td>
</tr>
<tr class="odd">
<td style="border:1px solid black;">非ページ プール サイズの最大値</td>
<td style="border:1px solid black;">50</td>
<td style="border:1px solid black;">100</td>
<td style="border:1px solid black;">200</td>
<td style="border:1px solid black;">256</td>
<td style="border:1px solid black;">256</td>
<td style="border:1px solid black;">256</td>
</tr>
</tbody>
</table>
  
テストを行った結果、エントリ レベルのコンピュータでは 256 MB、ハイ エンド コンピュータでは 1024 MB で十分であることがわかりました。このサイズであれば、メモリ容量いっぱいの作業セットを格納することもできます。
  
#### キャッシュ メモリの調整
  
キャッシュ シナリオでは、メモリを以下の目的で使用します。
  
1.  **未処理の要求オブジェクト** 未処理の要求オブジェクト数は ISA Server への接続数に対応します。1 つの接続につきメモリが約 15 KB 必要であるため、接続数が 10,240 である場合、Web プロキシ メモリの作業セットには未処理の要求オブジェクト用に 10,000 x 15 KB = 約 150 MB のメモリが割り当てられます。
  
2.  **キャッシュ ディレクトリ** キャッシュ オブジェクトごとに 32 バイトのエントリが追加されます。キャッシュ ディレクトリのサイズは、キャッシュ サイズと平均応答サイズによって決まります。たとえば、5,000,000 のオブジェクト (1 つのサイズが 10 KB) が格納された 50 GB のキャッシュには、32 x 5,000,000 = 153 MB のキャッシュ ディレクトリが必要です。
  
3.  **メモリ キャッシュ** メモリ キャッシュの目的は、要求頻度のキャッシュ オブジェクトへの要求にメモリ内で対応し、ディスク キャッシュ フェッチを減らすことです。メモリ キャッシュの効果はフォワード キャッシュとリバース キャッシュでは大きく異なります。リバース キャッシュ シナリオでは、ISA Server が Web サイトをホストし、データの量はそれほど多くありません。このような場合、すべてのキャッシュ可能コンテンツをメモリ キャッシュにロードすることができ、それによってディスク アクセスがまったく不要になるため、パフォーマンスの向上に多大な効果があります。フォワード キャッシュ シナリオの場合は、キャッシュ可能コンテンツの量がほとんど無限であるため、メモリ キャッシュがどれほど大きくても、ヒットのかなりの部分が常にディスク キャッシュで処理されることになります。したがって、メモリ キャッシュのサイズはパフォーマンスの向上にそれほど大きな効果を及ぼしません。
  
メモリ キャッシュの既定サイズは物理メモリの合計サイズの 50% ですが、この設定は変更が可能です。メモリ キャッシュ サイズの調整は試行錯誤によって行います。まず、メモリの最大ヒット数に対応できるだけの大きなサイズであることが必要です (パフォーマンス カウンタ \\ISA Server Cache\\Memory Usage Ratio Percent (%) の値から、キャッシュ フェッチ全体に対するメモリ フェッチの比率がわかります)。ただし、ISA Server のメモリ キャッシュに対するメモリ割り当てが大きすぎると、物理メモリが不足し、他のデータをロードできなくなるため、不要なハード ページ フォルトを引き起こす可能性があります。
  
ハード ページ フォルトは急激なパフォーマンス低下の原因となります。この問題を解決するには、メモリを増やすか、メモリ キャッシュのサイズを小さくします。
  
上記の点を考慮したうえで、キャッシュ メモリのサイズを調整するには、以下の手順を実行します。
  
1.  ディスク キャッシュのサイズを調整します (「ディスク キャパシティの見積もり」を参照してください)。
  
2.  以下の値を合計し、必要なメモリ サイズを見積もります。
  
    1.  未処理の要求オブジェクト (15 KB \* ピーク時に確立される接続の数)
  
    2.  キャッシュ ディレクトリ サイズ (32 \* キャッシュ内の URL の数)
  
    3.  メモリ キャッシュ サイズ - リバース キャッシュの場合は、作業セット サイズの 1 ～ 2 倍に設定します。フォワード キャッシュの場合は、ハード ページ フォルトが発生しない程度に、できる限り大きな値に設定します。新たに導入する ISA Server システムの必要メモリ容量を見積もるときには、物理メモリ サイズの 10 ～ 50% をメモリ キャッシュとして確保してください。
  
    4.  システム メモリ - 1 つの接続につき約 2 KB が必要であり、それに予備の 50 MB を加えます (50 MB + 2 KB \* ピーク時に確立される接続の数)
  
    5.  他のプロセスへの割り当て - 最低 100 MB
  
3.  ステップ 2 で算出した合計メモリ サイズのうち見積もりによって得た割合をメモリ キャッシュのサイズとします。ハードウェア システムにステップ 2 で算出した合計メモリ サイズを超えるメモリがある場合は、メモリ キャッシュの割合をさらに増やすことができます。最大負荷においてすべての物理メモリが使用され、しかもハード ページ フォルトが発生しないようにすることを目指します。
  
4.  メモリの使用状況を監視し、その結果に基づいてメモリ キャッシュのサイズを変更してください。メモリの使用状況を確認するには、次のパフォーマンス カウンタが役立ちます。
  
    ```
        \ISA Server Cache\Memory Cache Allocated Space (KB)  
        \ISA Server Cache\Memory URL Retrieve Rate (URL/sec)  
        \ISA Server Cache\Memory Usage Ratio Percent (%)  
        \ISA Server Cache\URLs in Cache  
        \Memory\Pages/sec  
        \Memory\Pool Nonpaged Bytes  
        \Memory\Pool Paged Bytes  
        \Process(W3PROXY)\Working Set  
        \TCP\Established Connections  
    ```

5.  既に説明したとおり、メモリが正しく調整されていないことを示す最も重要な徴候は、
  
    ```
        \\Memory\\Pages/sec  
    ```  
が最大負荷において大きな値を示す (10 を超える) ことです。その場合には、まずメモリ キャッシュのサイズを小さくし、次にメモリの増設が必要かどうかを検討します。  
#### boot.ini の /3 GB スイッチの使用
  
メモリが 2 GB を超える大規模システムでは、Windows 2000 Advanced Server の 3 GT RAM チューニング機能を使用して、プロセス メモリ空間を 3 GB のアプリケーション メモリと 1 GB のシステム メモリに分割することができます。この機能によって、プロセスはユーザー領域の 2 GB を超える RAM を使用できます。この機能を有効にするには、boot.ini ファイルにスイッチ /3GB を追加します (詳細については、Microsoft サポート技術情報の Knowledge Base の文書 [171793](http://support.microsoft.com/kb/171793) を参照してください)。
  
この機能は ISA Server にとって有益であり、特にリバース キャッシュ シナリオで大規模な Web サイト (たとえば大きな作業セットが処理されるようなサイト) をホストする場合に大きな効果があります。ただし、この機能を使用すると非ページ プールの最大サイズが縮小されるため (256 MB から 128 MB に減少します)、同時 TCP 接続の最大数も減少します。
  
[](#mainsection)[ページのトップへ](#mainsection)
  
### ISA Server シナリオの調整
  
ここでは、シナリオごとのパフォーマンスの調整について説明します。
  
#### ファイアウォール シナリオの調整
  
どのようなファイアウォール シナリオにとっても、カーネル モード データ ポンピング (KMDP) がパフォーマンスの向上をもたらす最大の要因です。KMDP を有効にするには、IP ルーティングを有効にします (既定では無効になっています)。ただし、KMDP を有効にしても、すべてのプロトコルで KMDP が使用されるわけではありません。さらに、あるプロトコルについて KMDP を有効にした場合、必ずしもユーザー モード データ ポンピング (UMDP) を使用した場合よりパフォーマンスが向上するとは限りません。KMDP のメリットを最大限に引き出すためには、ワークロードの中で最もキャパシティを浪費するプロトコルについて KMDP を有効にすることをお勧めします。
  
キャパシティを浪費するプロトコルには、以下のようなものがあります。
  
-   **HTTP** - 最も広く使用されているプロトコルであり、インターネット トラフィックの 70 ～ 80% を占めます。HTTP は単一チャネル プロトコルであり、データと制御ヘッダーが同じ TCP 接続で伝送されるため、HTTP で KMDP を使用できるのは次の場合だけです。
  
    1.  アウトバウンド ファイアウォール クライアント (リモート WinSock またはこれを略して RWS ともいいます) で使用する。
  
    2.  HTTP ポートにアプリケーション フィルタを使用していない (そのためには、既定で有効になっている HTTP リダイレクタ フィルタを無効にする必要があります)。HTTP リダイレクタ フィルタが有効である場合、透過的キャッシュが無効になるため、キャッシュ パフォーマンスを改善するためにも、このフィルタを無効にすることをお勧めします (以下のフォワード キャッシュ パフォーマンスの調整に関する節を参照してください)。
  
-   **FTP** - 大きなファイルの転送に広く使用されているプロトコルです。ISA Server では、IP ルーティングが有効である場合、FTP アプリケーション フィルタ (既定で有効) のデータ チャネルで常に KMDP が使用されます。

-   **ストリーミング メディア** - オーディオおよびビデオの転送プロトコル セットです。ISA Server に付属のストリーミング メディア アプリケーション フィルタは、MMS (Microsoft Media Streaming)、PNM (Progressive Network Media by Real Media)、およびインターネット標準の RTSP (Real Time Streaming Protocol) をサポートしています。これらのプロトコルはいずれも UDP (伝送路の障害でフェール オーバーが発生した場合は TCP) 上のセカンダリ データ チャネルを使用するため、KMDP の使用が可能です。
  
    次の表は、すべてのトランスポート/クライアント/フィルタ構成で行った ISA Server パフォーマンス テストの結果です。
  
    **表 4 ストリーミング メディアに対する ISA Server のスループット**
  
    ![](images/Cc750615.isprfp08(ja-jp,TechNet.10).gif)
  
    この表を見ると、KMDP の方が UMDP よりパフォーマンスの面で優れていることがわかります。しかし、KMDP を使用した構成はあまり使用されません。UDP はサーバーとクライアントとの間のプロトコルとしては望ましいものの、ストリーミング メディア アプリケーション フィルタを有効にする必要があるため、他のほとんどのケース (TCP、RWS) では UMDP が使用されます。ただし、さいわいなことに、HTTP 上でのストリーミング メディア データは、RWS クライアントでは KMDP で転送されます (上記の HTTP に関する説明を参照してください)。
  
その他のプロトコルは、広く使用されているものもありますが (メール プロトコル、DNS、ICMP など)、上の表に示したプロトコルに比べてキャパシティが小さいため、プロトコル自体のパフォーマンスを改善しても目に見える効果は期待できません。
  
#### キャッシュ シナリオの調整
  
フォワード キャッシュとリバース キャッシュではワークロードに違いがあり、使用する目的も異なります。したがって、パフォーマンスの調整上の考慮点も異なっています。この点について以下で説明します。
  
#### フォワード キャッシュの調整
  
フォワード キャッシュの目的は、インターネット接続の応答時間を短縮し、帯域幅を縮小することです (これは実際にはサービス品質を高めながらネットワーク アクセス コストを削減するという目標と同じです)。したがって、フォワード キャッシュの究極的なパフォーマンス目標はヒット率を最大化することです。さいわい、ISA Server はヒット (キャッシュで処理される) のコストがミス (ネットワークで処理される) のコストより (全体的なリソース使用の点で) 小さくなるように設計されており、フォワード キャッシュのパフォーマンス目標と合致します。
  
この考え方に従うと、最適なパフォーマンスを達成するには、ヒット率を最大化できるだけの十分なディスク領域を確保することが最善の方法です4 (詳細については、「ディスク キャパシティの見積もり」を参照してください)。ディスク キャッシュ構成を計画するときには、ディスクの合計サイズを見積もると共に (ヒット率の最大化を目的とします)、ディスクの数についても検討します (ディスクあたりのヒット数がディスクの最大 I/O 速度を超えないようにします)。
  
ディスク構成が決定したら、次にメモリ キャッシュのサイズを定義します。ISA Server では、メモリ キャッシュの既定サイズは物理メモリの合計サイズの 50% です。ほとんどの場合はこの値で十分ですが、この値が危険となる場合もあれば、まったく意味をなさない場合もあります。詳細については、「メモリ容量の見積もり」を参照してください。
  
キャッシュ パフォーマンスに関して重要な留意点があります。システムがインターネット接続の帯域幅に拘束されておらず (「単一エントリ レベル ISA Server コンピュータ」を参照)、ISA Server システムを「CPU 使用率の最大化を目的としたシステム設計」の説明に従って設計した場合は、明示的なプロキシ キャッシュを使用してください。そのためには、ユーザー ブラウザを企業 Web プロキシ (ISA Server) の使用が可能な設定にします。Microsoft Internet Explorer 5 以上では、Web プロキシを各企業のポリシーに基づいて手動または自動で設定できます。この設定を行う方法の詳細については、『Advantages of Using MS Internet Explorer 5 in Your Business』 (英語) を参照してください。
  
#### Web 発行の調整
  
Web 発行 (リバース キャッシュ) の目的は、Web アクセスの応答時間を短縮し、バックエンド Web サーバーの負荷を軽減することです (これもサービス品質の向上と CPU コストの削減につながります)。フォワード キャッシュの場合と同様、この目的はヒット率を最大化することを意味します。ただし、根本的な違いは、リバース キャッシュの作業セットの方がはるかに小さいことです。そのため、ほとんどの場合、作業セット全体を物理メモリで扱うことができます。
  
したがって、リバース キャッシュの場合は、まずメモリ容量の見積もりから始めます。大規模な Web サイトであっても、すべての静的データを数ギガバイトの 1 つのディスクに格納できるため、ディスク キャパシティの重要性は高くありません。
  
もう 1 つ検討が必要な点として、内部ネットワークに接続するネットワーク カードの帯域幅があります。着信方向の帯域幅が大きい場合でも (インターネット接続に対応するため)、内部ネットワークの帯域幅は小さいことがあります。これは、通常のヒット率が 80 ～ 90% の範囲にあり、バックエンド Web サーバーでは応答トラフィックの 10 ～ 20% しか処理しないからです。5したがって、内部ネットワーク カードの最大帯域幅を縮小することが可能であり、ネットワーク インフラストラクチャのコスト削減にもつながります。
  
[](#mainsection)[ページのトップへ](#mainsection)
  
### ISA Server 機能の調整
  
#### クライアントの調整
  
クライアントの調整は ISA Server のパフォーマンスに多大な影響を及ぼします。
  
パフォーマンスの向上を図る場合は、以下のガイドラインに従ってください。
  
-   アウトバウンド ファイアウォールについては、クライアントとして RWS を使用した方が (SecureNAT と比較して) パフォーマンスの向上につながります。RWS による効果は、特に HTTP、FTP、ストリーミング メディアなどの高トラフィック プロトコルを使用する場合に顕著です (KMDP を使用すると、2 ～ 3 倍のパフォーマンス向上が期待できます)。
  

-   フォワード キャッシュは透過的キャッシュよりはるかに高速です。これは、フォワード キャッシュの場合、クライアントが ISA Server に明示的に接続するため、接続のキープアライブ率が透過的キャッシュの場合よりはるかに高く、しかも同時接続の総数が減少するからです。したがって、すべての内部 Web ブラウザが ISA Server と直接通信する構成をお勧めします (そのためには、中央ブラウザ インストールを全社レベルのポリシーに従って設定するか、インターネット ブラウザのインターネット自動設定検出を使用します)。
  

-   ストリーミング メディア クライアントが ISA Server にもたらす負荷は、以下の場合に小さくなります。
  
    1.  ストリーミング メディア フィルタを有効にした場合は、プレーヤーがメディアを使用するためのプロトコルを RWS クライアントの場合は HTTP、SecureNAT クライアントの場合は UDP に設定します。
  
    2.  ストリーミング メディア フィルタが無効である場合は、RWS クライアントだけがメディアを再生できます。この場合は、メディアの転送プロトコルとして TCP を使用するようにお勧めします。

#### ポリシーの調整
  
ISA Server ポリシーを調整する場合は、以下のパフォーマンス ガイドラインに従ってください。
  
-   ルールの数をできる限り少なくします (ルールの処理による負荷はルール数に比例して増大するからです)。たとえば、送信先を指定するルールは、送信先ごとに 1 つのルールを使用するのではなく、大きな送信先セットに 1 つのルールを対応付けた方が効率的です。
  

-   拒否ルールより許可ルールに比重を置きます (拒否ルールをすべてチェックしてから許可ルールをチェックし、最初の許可ルールが見つかったときにルールのチェックが終了するからです)。
  

-   ファイアウォール ポリシーは接続が確立されるときにのみチェックされるため、ファイアウォール ポリシーによるオーバーヘッドは確立された接続上で転送されるデータと比較すると取るに足らないものです。キャッシュ ポリシーは要求ごとにチェックされます。したがって、キャッシュ ポリシーに伴うオーバーヘッドはファイアウォール ポリシーの場合よりはるかに大きくなります。
  

-   DNS ルックアップに伴う問題が発生しないように対策を講じます。送信先セット内のすべての送信先を解決可能にし、可能であれば近隣 DNS をセットアップしてください。

#### 認証の調整
  
認証のパフォーマンスを調整するときには、以下の点を考慮してください。
  
-   ファイアウォール認証が関係するのは RWS クライアントの場合だけです。1 つのセッションで多くの接続が確立され、それよりさらに多くのパケットが転送されますが、ファイアウォール認証は 1 つのセッションについて 1 回しか行われないため、オーバーヘッドはごくわずかしかありません。
  

-   キャッシュ認証の場合は、ファイアウォール認証よりチェックの頻度が高く、認証方式によっては再認証率も高くなります。また、認証の実行に伴う処理の量も認証方式によって異なります。次の表は、各認証方式の特徴を示しています。
  
**表 5 ISA Server の認証パフォーマンス**

<table style="border:1px solid black;">
<colgroup>
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
<col width="20%" />
</colgroup>
<thead>
<tr class="header">
<th style="border:1px solid black;" >認証方式</th>
<th style="border:1px solid black;" >強度</th>
<th style="border:1px solid black;" >認証のタイミング</th>
<th style="border:1px solid black;" >要求あたりのオーバーヘッド</th>
<th style="border:1px solid black;" >バッチあたりのオーバーヘッド</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="border:1px solid black;">基本</td>
<td style="border:1px solid black;">低い</td>
<td style="border:1px solid black;">要求ごと</td>
<td style="border:1px solid black;">低い</td>
<td style="border:1px solid black;">なし</td>
</tr>
<tr class="even">
<td style="border:1px solid black;">ダイジェスト</td>
<td style="border:1px solid black;">中程度</td>
<td style="border:1px solid black;">時間/カウンタ値ごと</td>
<td style="border:1px solid black;">なし</td>
<td style="border:1px solid black;">高い</td>
</tr>
<tr class="odd">
<td style="border:1px solid black;">NTLM</td>
<td style="border:1px solid black;">高い</td>
<td style="border:1px solid black;">接続ごと</td>
<td style="border:1px solid black;">なし</td>
<td style="border:1px solid black;">高い</td>
</tr>
<tr class="even">
<td style="border:1px solid black;">Kerberos</td>
<td style="border:1px solid black;">高い</td>
<td style="border:1px solid black;">接続ごと</td>
<td style="border:1px solid black;">なし</td>
<td style="border:1px solid black;">中程度</td>
</tr>
</tbody>
</table>
  
-   キャッシュ認証のパフォーマンスに関して留意しなければならない点がもう 1 つあります。キャッシュ認証は Web プロキシ リスナ レベル (アレイ プロパティの \[着信方向の Web 要求\] タブと \[発信方向の Web 要求\] タブにある \[認証されていないユーザーに識別情報を求める\] をオンにします) とルール レベルのいずれかで設定できることです。すべての Web アクセスについて認証が必要な場合は Web プロキシ リスナ レベルで設定し、そうでない場合 (ルールによって必要となった場合のみ認証を行う場合) はルール レベルで設定します。
  
#### フィルタの調整
  
フィルタはそれ自体が CPU サイクルを必要とするため、パフォーマンスに直接の影響を及ぼします。極端な場合には、フィルタがリソースを必要とするために、ISA Server のパフォーマンスがフィルタを使用しない場合に比べて大幅に低下することもあります。したがって、以下のことを行うようにお勧めします。
  
-   使用するフィルタのパフォーマンスを計測し、フィルタの調整によって効率を最大限に高めます。可能であれば、フィルタではなく ISA Server ルールを使用することを検討してください (たとえば、アクセス ルールの送信先セットを使用したサイト ブロックの方が、同じ機能を持つ ISAPI フィルタより格段に効率的な場合があります)。
  

-   フィルタを作成する場合は、パフォーマンスが最高となるようにフィルタの最適化を行ってください。これはどのようなソフトウェアにも当てはまりますが、ミッションクリティカルなファイアウォール/プロキシ サーバーの場合は特にこのような最適化が重要です。
  

-   KMDP を使用するプロトコルにアプリケーション フィルタを追加して UMDP にダウングレードすることは避けてください (たとえば、セカンダリ データ チャネルはできるだけ KMDP のままにしてください)。

#### 暗号化の調整
  
ファイアウォール シナリオの場合、暗号化オプションの調整とは実際のところ Windows VPN の調整を意味します。VPN のパフォーマンスに関する詳細については、「Windows 2000 VPN: Enterprise Performance with Server-Based Flexibility」と題されたレポート (英語) を参照してください。
  
キャッシュ シナリオの場合は SSL (HTTPS とも呼ばれます) を使用します。ただし、使用方法はフォワード キャッシュと Web 発行では異なります。Web 発行では、ISA Server が SSL セッションの終端点として機能します。つまり、ISA Server がクライアントと連携して SSL ハンドシェイクと暗号化を行います。このとき、バックエンド サーバーも使用されます。
  
フォワード キャッシュでは、ISA Server は単にトンネルとして機能し、ある場所から別の場所へパケットを転送するだけで、暗号化やハンドシェイクは行いません。したがって、トンネリングのパフォーマンスは、インターネットから取得した暗号化されていないデータを扱う場合とほぼ同じです。
  
ISA Server 上の Web 発行において SSL を調整する場合は、以下のガイドラインに従ってください。
  
-   HTTPS 接続において暗号化を実行するためには、同じデータを HTTP 接続で転送する場合に比べて約 2 倍の CPU 能力が必要です。HTTPS 接続の作成に必要な CPU 能力は、HTTP 接続を作成する場合と比較すると桁違いに大きくなります。SSL 高速化ハードウェアのパフォーマンスは、製品情報によると PKI ソフトウェアの 2 ～ 10 倍です。このパフォーマンス向上がワークロードに与える影響は、1 つの接続で送信される要求の数によって異なります (このことは Web 発行にのみ当てはまります)。
  

-   リバース キャッシュで SSL を使用した場合は、実際の Web サイトで使用した場合とまったく同じように、データの暗号化と復号化を行います。ISA Server には、次の 2 つの SSL 接続モードがあります。
  
    1.  片方向 SSL - クライアントと ISA Server との通信に SSL が使用されます。ただし、ISA Server とバックエンド Web サーバーとの通信には通常どおり HTTP が使用されます。
  
    2.  双方向 SSL - どちらの通信チャネルにも SSL が使用されます。つまり、ISA Server はバックエンド Web サイトから送信された要求を復号化し、クライアントに応答を送信するときに再び暗号化します (別の暗号化キーを使用します)。
  
    4.  双方向 SSL では個々の要求について処理の量が片方向 SSL の 2 倍となるため、CPU 能力も片方向 SSL の 2 倍必要となります。
  
    このような理由から、以下のガイドラインに従うことが必要です。
  
    -   双方向 SSL は必要な場合のみ使用してください。ISA Server とバックエンド Web サーバーとの間の SSL チャネルは、既に保護されている内部ネットワーク通信にさらにセキュリティ対策を施すものです。
  
    -   すべての SSL コンテンツをキャッシュ不能にしないでください。HTTPS ストリームには、HTTP と同じように、プライベート Web ページ内のヒットとして共有可能なオブジェクト (イメージやアイコンなど) が数多く含まれています。HTTPS 接続上で転送されるパブリック データをキャッシュ可能にしたとしても、双方向 SSL のオーバーヘッドがパフォーマンスに与える影響は、片方向 SSL の場合と比較してもわずかなものでしかありません。影響を受けるのは、トラフィック全体から見ると小さな割合でしかないキャッシュ ミスだけだからです。
  
    -   フォワード キャッシュ シナリオでは、SSL はトンネリング プロトコルとして機能します。そのため、コンテンツはキャッシュされません。それに伴い、インターネットのスループットが向上しますが (非暗号化伝送と比較して)、SSL プロトコルのトンネリングによる処理オーバーヘッドは、データを暗号化する場合よりはるかに小さいものです。
  
[](#mainsection)[ページのトップへ](#mainsection)
  
### ワークロードの見積もり
  
ここでは、ワークロードを見積もる方法について説明します (ワークロードの見積もりは大規模企業戦略および公開戦略において必要です)。ワークロードの見積もり方法は大きく分けて 2 つあり、ISA Server を既存システムの代替システムまたは追加システムとして導入するか、まったく新しいシステムとして導入するかによって使い分けます。前者の場合は、既存のシステムにワークロードの見積もりに役立つ有益な情報ソースがあります (Web ログ、ファイアウォール ログ、パフォーマンス カウンタなど)。後者の場合は、ワークロードの見積もりが困難となる可能性があり、小型プロトタイプの構築および実行が必要となることもあります。
  
#### 既存のログおよびパフォーマンス カウンタを使用した見積もり
  
ワークロード パラメータを計算する場合は、ログが最良の情報ソースです。Web キャッシュ サーバーには、通常、個々の Web トランザクションに関する記録が残っており、クライアント名、サーバー名、IP アドレス、要求された URL、応答のサイズ、時刻と状態や、応答がキャッシュとインターネットのどちらから行われたかなどの情報を得ることができます。ファイアウォールにも、接続ごとに送信先ポート (使用されたプロトコル) が記録されています。
  
応答の平均サイズ、平均時間、ヒット率、キャッシュ可能比率、プロトコル分布など、簡単に計算できるパラメータもあれば、以下に挙げるような計算が困難なパラメータもあります。
  
-   **作業セット サイズ** (フォワード キャッシュ) : キャッシュ内のデータによって応答した要求を調べ、各 URL がヒットした回数を数えます。ヒット数の多い URL から順に並べていくと、明確な変化点のある Zipf 型の分布となります。この点より左側は URL の数は少ないものの個々の URL のヒット数は多く、右側は URL の数は多いものの個々の URL のヒット数は少なくなっています (この分布をグラフにすると、変化点の位置がはっきりとわかります)。この変化点の左側に位置する要求頻度のオブジェクトの合計サイズが作業セット サイズとなります。
  
    次に、URL 分布図の例を示します (これは Microsoft 社内の 2001 年 7 月のプロキシ ログを基に作成したものです)。
  
    ![](images/Cc750615.isprfp09(ja-jp,TechNet.10).gif)
  
    この分布図を見ると、2 日間で作業セットがどのように変わるかがわかります。1 日目の作業セットが約 4GB であるのに対し、2 日目は 3.3 GB しかありません (変化点の URL 数は 150,000 です)。
  
-   **接続あたりの要求数** (ファイアウォール シナリオでのアウトバウンド HTTP) : Web ログを開き、クライアントとサーバーの組み合わせごとに要求数を数えます。各要求の時刻を基に、連続する 2 つの要求の間隔を確認することができます。IE では、1 分間操作が行われなければ接続が閉じるため、1 分を超える間隔が空いている場合は、接続がいったん閉じ、再び確立されたことを意味します。連続する要求の送信間隔が 1 分に満たない場合は、それらの要求が同じ接続で送信されたと考えられます。また、IE ではターゲットごとに 2 つの接続が確立されるため、1 分のアイドル時間内の平均接続数を 2 で割った値が 1 接続あたりの平均要求数となります。

インターネットの使用率は 1 日の間でも時間帯によって異なり、1 週間の間でも一定しないため、複数のログを調査対象とし、できるだけ営業日のログ情報を調べることが必要です。
  
リアルタイム監視カウンタ (Windows システムでは "パフォーマンス カウンタ" といいます) も有益な情報ソースです。既存のファイアウォール サーバーおよびキャッシュ サーバーには、発生したイベントの計測値を示すカウンタがあります。
  
#### プロトタイプを使用した見積もり
  
ISA Server をまったく新しいシステムとして導入する場合もあります。その場合、ほとんどが公開戦略カテゴリに属するシステムであり、将来的に Web サイトや Web サービスを提供することを前提としています。このホワイト ペーパーは、Web サイトのシミュレーションとパフォーマンス モデリングについて、さまざまな面から説明することを目的としていません。?Web キャパシティ プランニングの詳細については、<http://www.microsoft.com/japan/technet/archive/itsolutions/ecommerce/default.mspx> を参照してください。
  
[](#mainsection)[ページのトップへ](#mainsection)
  
### 参考資料
  
このホワイト ペーパーで使用した市場調査報告書 : 『Internet Connectivity Services: A Demand-Side View, 2001, report 26023』 Steven T. Harris 著、2001 年 12 月 (IDC)
  
マイクロソフトは、お客様が ISA Server を問題なく展開し、管理できることを目指して情報を共有したいと考えております。
  
ISA Server の最新情報については、<http://www.microsoft.com/japan/isaserver/> を参照してください。
  
Microsoft .NET の最新情報については、<http://www.microsoft.com/japan/net/> を参照してください。
  
Windows 2000 Professional および Windows 2000 Advanced Server の最新情報については、<http://www.microsoft.com/japan/windows/> を参照してください。
  
Microsoft Knowledge Base の Microsoft 製品に関するサポート情報およびお客様でご利用いただけるツールについては、[http://support.microsoft.com/default.aspx?scid=fh;ja;KBHOWTO](http://support.microsoft.com/default.aspx?scid=fh;ja;kbhowto) を参照してください。
  
このドキュメントに記載されている情報は、このドキュメントの発行時点におけるマイクロソフトの見解を反映したものです。変化する市場状況に対応する必要があるため、このドキュメントは、記載された内容の実現に関するマイクロソフトの確約とはみなされないものとします。また、発行以降に発表される情報の正確性に関して、マイクロソフトはいかなる保証もいたしません。
  
このドキュメントに記載された内容は情報提供のみを目的としており、明示または黙示に関わらず、これらの情報についてマイクロソフトはいかなる責任も負わないものとします。
  
お客様ご自身の責任において、適用されるすべての著作権関連法規に従ったご使用を願います。このドキュメントのいかなる部分も、米国 Microsoft Corporation の書面による許諾を受けることなく、その目的を問わず、どのような形態であっても、複製または譲渡することは禁じられています。ここでいう形態とは、複写や記録など、電子的な、または物理的なすべての手段を含みます。ただしこれは、著作権法上のお客様の権利を制限するものではありません。
  
マイクロソフトは、このドキュメントに記載されている内容に関し、特許、特許申請、商標、著作権、またはその他の無体財産権を有する場合があります。別途マイクロソフトのライセンス契約上に明示の規定のない限り、このドキュメントはこれらの特許、商標、著作権、またはその他の無体財産権に関する権利をお客様に許諾するものではありません。
  
? 2001 Microsoft Corporation. All rights reserved.
  
Microsoft、Active Directory、Outlook、および Windows は、米国およびその他の国における Microsoft Corporation の登録商標または商標です。
  
記載されている会社名、製品名には、各社の商標のものもあります。
  
1 プロセッサ数を倍にしたときにアプリケーションが処理できるトランザクションの数も倍になることを直線的スケーリングといいます。プロセッサ数を倍にしたときにアプリケーションが処理できるトランザクションの数がどれだけ増えたかを示す増加率のことをスケール係数といいます。したがって、直線的スケーリングが可能なシステムのスケール係数は 2 となります。
  
2 デュアル プロセッサ コンピュータには 2 つのクラスがあります。デスクトップ クラスのプロセッサ (Pentium など) を搭載したワークステーションとサーバー クラスのプロセッサ (Xeon など) を搭載したサーバーです。前者の方が低価格で、ハイエンド エントリ レベルに分類されるのに対し、後者はサーバー アプリケーション向けにパフォーマンスおよびキャパシティが強化されています。
  
3 キャッシュ オブジェクトがリフレッシュされた場合、しばらくは同じオブジェクトの新旧のコピーがディスク領域を使用します。キャッシュ オブジェクトの元のバージョンが使用していた領域は割り当てが解除されますが、別のオブジェクトが使用するまで、しばらくの間 (実際の時間は平均リフレッシュ率によって異なります) 解放されません。
  
4 実際には、まずピーク要求率に対応できるだけの CPU 能力と内部ネットワーク帯域幅があることを確認します。これらが十分でない場合、CPU または帯域幅の不足によって応答時間が許容できないレベルまで増加します。
  
5 これは、ヒット、ミス、およびキャッシュ不能応答サイズの分布がほぼ同じであることを前提としています。
  
[](#mainsection)[ページのトップへ](#mainsection)
